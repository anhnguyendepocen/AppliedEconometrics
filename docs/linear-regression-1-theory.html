<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>8 Linear Regression 1: Theory | Lecture Note for Applied Econometrics</title>
  <meta name="description" content="8 Linear Regression 1: Theory | Lecture Note for Applied Econometrics">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="8 Linear Regression 1: Theory | Lecture Note for Applied Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Linear Regression 1: Theory | Lecture Note for Applied Econometrics" />
  
  
  

<meta name="author" content="Yuta Toyama">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="a-review-of-statistics.html">
<link rel="next" href="linear-regression-2-implementation-in-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#about-this"><i class="fa fa-check"></i><b>1.1</b> About this</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#update-april-23-2019"><i class="fa fa-check"></i><b>1.2</b> Update: April 23, 2019</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#update-april-16-2019"><i class="fa fa-check"></i><b>1.3</b> Update: April 16, 2019</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#acknowledgement-as-of-april-16-2019"><i class="fa fa-check"></i><b>1.4</b> Acknowledgement (as of April 16, 2019)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html"><i class="fa fa-check"></i><b>2</b> Introduction to the course</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#what-is-econometrics"><i class="fa fa-check"></i><b>2.1</b> What is econometrics?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#why-do-we-need-to-learn-computation"><i class="fa fa-check"></i><b>2.2</b> Why do we need to learn computation</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#why-do-we-use-r"><i class="fa fa-check"></i><b>2.3</b> Why do we use R?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html"><i class="fa fa-check"></i><b>3</b> Introduction of <code>R</code> and <code>R studio</code></a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#getting-started"><i class="fa fa-check"></i><b>3.1</b> Getting Started</a></li>
<li class="chapter" data-level="3.2" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#helps"><i class="fa fa-check"></i><b>3.2</b> Helps</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#quick-tour-of-rstudio"><i class="fa fa-check"></i><b>3.3</b> Quick tour of Rstudio</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#basic-calculations"><i class="fa fa-check"></i><b>3.4</b> Basic Calculations</a></li>
<li class="chapter" data-level="3.5" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#getting-help"><i class="fa fa-check"></i><b>3.5</b> Getting Help</a></li>
<li class="chapter" data-level="3.6" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#installing-packages"><i class="fa fa-check"></i><b>3.6</b> Installing Packages</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-and-programming.html"><a href="data-and-programming.html"><i class="fa fa-check"></i><b>4</b> Data and Programming</a><ul>
<li class="chapter" data-level="4.1" data-path="data-and-programming.html"><a href="data-and-programming.html#data-types"><i class="fa fa-check"></i><b>4.1</b> Data Types</a></li>
<li class="chapter" data-level="4.2" data-path="data-and-programming.html"><a href="data-and-programming.html#data-structures"><i class="fa fa-check"></i><b>4.2</b> Data Structures</a></li>
<li class="chapter" data-level="4.3" data-path="data-and-programming.html"><a href="data-and-programming.html#vectors"><i class="fa fa-check"></i><b>4.3</b> Vectors</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#basics-of-vectors"><i class="fa fa-check"></i><b>4.3.1</b> Basics of vectors</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#useful-functions-for-creating-vectors"><i class="fa fa-check"></i><b>4.3.2</b> Useful functions for creating vectors</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-and-programming.html"><a href="data-and-programming.html#subsetting"><i class="fa fa-check"></i><b>4.3.3</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-and-programming.html"><a href="data-and-programming.html#vectorization"><i class="fa fa-check"></i><b>4.4</b> Vectorization</a></li>
<li class="chapter" data-level="4.5" data-path="data-and-programming.html"><a href="data-and-programming.html#logical-operators"><i class="fa fa-check"></i><b>4.5</b> Logical Operators</a></li>
<li class="chapter" data-level="4.6" data-path="data-and-programming.html"><a href="data-and-programming.html#matrices"><i class="fa fa-check"></i><b>4.6</b> Matrices</a><ul>
<li class="chapter" data-level="4.6.1" data-path="data-and-programming.html"><a href="data-and-programming.html#basics"><i class="fa fa-check"></i><b>4.6.1</b> Basics</a></li>
<li class="chapter" data-level="4.6.2" data-path="data-and-programming.html"><a href="data-and-programming.html#matrix-calculations"><i class="fa fa-check"></i><b>4.6.2</b> Matrix calculations</a></li>
<li class="chapter" data-level="4.6.3" data-path="data-and-programming.html"><a href="data-and-programming.html#getting-information-for-matrix"><i class="fa fa-check"></i><b>4.6.3</b> Getting information for matrix</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="data-and-programming.html"><a href="data-and-programming.html#lists"><i class="fa fa-check"></i><b>4.7</b> Lists</a></li>
<li class="chapter" data-level="4.8" data-path="data-and-programming.html"><a href="data-and-programming.html#data-frames"><i class="fa fa-check"></i><b>4.8</b> Data Frames</a></li>
<li class="chapter" data-level="4.9" data-path="data-and-programming.html"><a href="data-and-programming.html#programming-basics--control-flow-"><i class="fa fa-check"></i><b>4.9</b> Programming Basics -Control flow-</a><ul>
<li class="chapter" data-level="4.9.1" data-path="data-and-programming.html"><a href="data-and-programming.html#ifelse"><i class="fa fa-check"></i><b>4.9.1</b> if/else</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="data-and-programming.html"><a href="data-and-programming.html#for-loop"><i class="fa fa-check"></i><b>4.10</b> <code>for</code> loop</a></li>
<li class="chapter" data-level="4.11" data-path="data-and-programming.html"><a href="data-and-programming.html#functions"><i class="fa fa-check"></i><b>4.11</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-frame.html"><a href="data-frame.html"><i class="fa fa-check"></i><b>5</b> Data frame</a><ul>
<li class="chapter" data-level="5.1" data-path="data-frame.html"><a href="data-frame.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="data-frame.html"><a href="data-frame.html#load-csv-file"><i class="fa fa-check"></i><b>5.2</b> Load csv file</a></li>
<li class="chapter" data-level="5.3" data-path="data-frame.html"><a href="data-frame.html#examine-dataframe"><i class="fa fa-check"></i><b>5.3</b> Examine dataframe</a></li>
<li class="chapter" data-level="5.4" data-path="data-frame.html"><a href="data-frame.html#subsetting-data"><i class="fa fa-check"></i><b>5.4</b> Subsetting data</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="exercise-1.html"><a href="exercise-1.html"><i class="fa fa-check"></i><b>6</b> Exercise 1</a><ul>
<li class="chapter" data-level="6.1" data-path="exercise-1.html"><a href="exercise-1.html#update-as-of-10am-april-18th"><i class="fa fa-check"></i><b>6.1</b> Update (as of 10am, April 18th)</a></li>
<li class="chapter" data-level="6.2" data-path="exercise-1.html"><a href="exercise-1.html#question-examine-the-law-of-large-numbers-through-numerical-simulations"><i class="fa fa-check"></i><b>6.2</b> Question: Examine the law of large numbers through numerical simulations</a><ul>
<li class="chapter" data-level="6.2.1" data-path="exercise-1.html"><a href="exercise-1.html#how-to-implement"><i class="fa fa-check"></i><b>6.2.1</b> How to implement</a></li>
<li class="chapter" data-level="6.2.2" data-path="exercise-1.html"><a href="exercise-1.html#what-to-submit"><i class="fa fa-check"></i><b>6.2.2</b> What to submit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html"><i class="fa fa-check"></i><b>7</b> A Review of Statistics</a><ul>
<li class="chapter" data-level="7.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#estimation"><i class="fa fa-check"></i><b>7.1</b> Estimation</a><ul>
<li class="chapter" data-level="7.1.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#properties-of-the-estimator"><i class="fa fa-check"></i><b>7.1.1</b> Properties of the estimator</a></li>
<li class="chapter" data-level="7.1.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#sample-mean-bary-is-unbiased-and-consistent"><i class="fa fa-check"></i><b>7.1.2</b> Sample mean <span class="math inline">\(\bar{Y}\)</span> is unbiased and consistent</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#hypothesis-testing"><i class="fa fa-check"></i><b>7.2</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="7.2.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.1</b> Central limit theorem</a></li>
<li class="chapter" data-level="7.2.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>7.2.2</b> Hypothesis testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html"><i class="fa fa-check"></i><b>8</b> Linear Regression 1: Theory</a><ul>
<li class="chapter" data-level="8.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#regression-framework"><i class="fa fa-check"></i><b>8.1</b> Regression framework</a></li>
<li class="chapter" data-level="8.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#theoretical-properties-of-ols-estimator"><i class="fa fa-check"></i><b>8.2</b> Theoretical Properties of OLS estimator</a></li>
<li class="chapter" data-level="8.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#interpretation-and-specifications-of-linear-regression-model"><i class="fa fa-check"></i><b>8.3</b> Interpretation and Specifications of Linear Regression Model</a><ul>
<li class="chapter" data-level="8.3.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#nonlinear-term"><i class="fa fa-check"></i><b>8.3.1</b> Nonlinear term</a></li>
<li class="chapter" data-level="8.3.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#log-specification"><i class="fa fa-check"></i><b>8.3.2</b> log specification</a></li>
<li class="chapter" data-level="8.3.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#dummy-variable"><i class="fa fa-check"></i><b>8.3.3</b> Dummy variable</a></li>
<li class="chapter" data-level="8.3.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#interaction-term"><i class="fa fa-check"></i><b>8.3.4</b> Interaction term</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#measures-of-fit"><i class="fa fa-check"></i><b>8.4</b> Measures of Fit</a></li>
<li class="chapter" data-level="8.5" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#statistical-inference"><i class="fa fa-check"></i><b>8.5</b> Statistical Inference</a><ul>
<li class="chapter" data-level="8.5.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#distribution-of-the-ols-estimators-based-on-asymptotic-theory"><i class="fa fa-check"></i><b>8.5.1</b> Distribution of the OLS estimators based on asymptotic theory</a></li>
<li class="chapter" data-level="8.5.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>8.5.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="8.5.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#confidence-interval"><i class="fa fa-check"></i><b>8.5.3</b> Confidence interval</a></li>
<li class="chapter" data-level="8.5.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#homoskedasticity-vs-heteroskedasticity"><i class="fa fa-check"></i><b>8.5.4</b> Homoskedasticity vs Heteroskedasticity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html"><i class="fa fa-check"></i><b>9</b> Linear Regression 2: Implementation in R</a><ul>
<li class="chapter" data-level="9.1" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#implementation-in-r"><i class="fa fa-check"></i><b>9.1</b> Implementation in R</a><ul>
<li class="chapter" data-level="9.1.1" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#preliminary-packages"><i class="fa fa-check"></i><b>9.1.1</b> Preliminary: packages</a></li>
<li class="chapter" data-level="9.1.2" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#empirical-setting-data-from-california-school"><i class="fa fa-check"></i><b>9.1.2</b> Empirical setting: Data from California School</a></li>
<li class="chapter" data-level="9.1.3" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#step-1-descriptive-analysis"><i class="fa fa-check"></i><b>9.1.3</b> Step 1: Descriptive analysis</a></li>
<li class="chapter" data-level="9.1.4" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#step-2-run-regression"><i class="fa fa-check"></i><b>9.1.4</b> Step 2: Run regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html"><i class="fa fa-check"></i><b>10</b> Linear Regression 3: Discussions on OLS Assumptions</a><ul>
<li class="chapter" data-level="10.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#endogeneity-problem"><i class="fa fa-check"></i><b>10.2</b> Endogeneity problem</a><ul>
<li class="chapter" data-level="10.2.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#omitted-variable-bias"><i class="fa fa-check"></i><b>10.2.1</b> Omitted variable bias</a></li>
<li class="chapter" data-level="10.2.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#correlation-v.s.-causality"><i class="fa fa-check"></i><b>10.2.2</b> Correlation v.s. Causality</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#multicollinearity-issue"><i class="fa fa-check"></i><b>10.3</b> Multicollinearity issue</a><ul>
<li class="chapter" data-level="10.3.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#perfect-multicollinearity"><i class="fa fa-check"></i><b>10.3.1</b> Perfect Multicollinearity</a></li>
<li class="chapter" data-level="10.3.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#imperfect-multicollinearity."><i class="fa fa-check"></i><b>10.3.2</b> Imperfect multicollinearity.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html"><i class="fa fa-check"></i><b>11</b> Exercise 2 (Problem Set 3)</a><ul>
<li class="chapter" data-level="11.1" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#rules"><i class="fa fa-check"></i><b>11.1</b> Rules</a></li>
<li class="chapter" data-level="11.2" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#question-1-omitted-variable-bias"><i class="fa fa-check"></i><b>11.2</b> Question 1: Omitted Variable Bias</a></li>
<li class="chapter" data-level="11.3" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#question-2-empirical-analysis-using-data-from-washington2008-aer"><i class="fa fa-check"></i><b>11.3</b> Question 2: Empirical Analysis using Data from Washington(2008, AER)</a><ul>
<li class="chapter" data-level="11.3.1" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#preliminary-data-cleaning"><i class="fa fa-check"></i><b>11.3.1</b> Preliminary: data cleaning</a></li>
<li class="chapter" data-level="11.3.2" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#questions"><i class="fa fa-check"></i><b>11.3.2</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lecture Note for Applied Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression-1-theory" class="section level1">
<h1><span class="header-section-number">8</span> Linear Regression 1: Theory</h1>
<div id="regression-framework" class="section level2">
<h2><span class="header-section-number">8.1</span> Regression framework</h2>
<ul>
<li>Let <span class="math inline">\(Y_i\)</span> be the dependent variable and <span class="math inline">\(X_{ik}\)</span> be k-th explanatory variable.
<ul>
<li>We have <span class="math inline">\(K\)</span> explantory variables (along with constant term)</li>
<li><span class="math inline">\(i\)</span> is an index for observations. <span class="math inline">\(i = 1,\cdots, N\)</span>.</li>
<li>Data (sample): <span class="math inline">\(\{ Y_i , X_{i1}, \ldots, X_{iK} \}_{i=1}^N\)</span></li>
</ul></li>
<li><strong>Linear regression model</strong> is defined as <span class="math display">\[ Y_{i}=\beta_{0}+\beta_{1}X_{1i}+\cdots+\beta_{K}X_{Ki}+\epsilon_{i} \]</span>
<ul>
<li><span class="math inline">\(\epsilon_i\)</span>: error term (unobserved)</li>
<li><span class="math inline">\(\beta\)</span>: coefficients</li>
</ul></li>
<li><strong>Assumptions for Ordinaly Least Squares (OLS) estimation</strong>
<ol style="list-style-type: decimal">
<li>Random sample: <span class="math inline">\(\{ Y_i , X_{i1}, \ldots, X_{iK} \}\)</span> is i.i.d. drawn sample
<ul>
<li>i.i.d.: identically and independently distributed</li>
</ul></li>
<li><span class="math inline">\(\epsilon_i\)</span> has zero conditional mean <span class="math display">\[
  E[ \epsilon_i | X_{i1}, \ldots, X_{iK}] = 0
  \]</span></li>
<li>Large outliers are unlikely: The random variable <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(X_{ik}\)</span> have finite fourth moments.</li>
<li>No perfect multicollinearity: There is no linear relationship betwen explanatory variables.</li>
</ol></li>
<li>OLS estimators are the minimizers of the sum of squared residuals: <span class="math display">\[
\min_{\beta_0, \cdots, \beta_K} \frac{1}{N} \sum_{i=1}^N (Y_i - (\beta_0 + \beta_1 X_{i1} + \cdots + \beta_K X_{iK}))^2
\]</span></li>
<li>Using matrix notation, we have the following analytical formula for the OLS estimator <span class="math display">\[
\hat{\beta} = (X&#39;X)^{-1} X&#39;Y
\]</span> where <span class="math display">\[
\underbrace{X}_{N\times (K+1)}=\left(\begin{array}{cccc}
1 &amp; X_{11} &amp; \cdots &amp; X_{1K}\\
\vdots &amp; \vdots &amp;  &amp; \vdots\\
1 &amp; X_{N1} &amp; \cdots &amp; X_{NK}
\end{array}\right),\underbrace{Y}_{N\times 1}=\left(\begin{array}{c}
Y_{1}\\
\vdots\\
Y_{N}
\end{array}\right),\underbrace{\beta}_{(K+1)\times 1}=\left(\begin{array}{c}
\beta_{0}\\
\beta_{1}\\
\vdots\\
\beta_{K}
\end{array}\right)            
\]</span></li>
</ul>
</div>
<div id="theoretical-properties-of-ols-estimator" class="section level2">
<h2><span class="header-section-number">8.2</span> Theoretical Properties of OLS estimator</h2>
<ul>
<li>We briefly review theoretical properties of OLS estimator.</li>
</ul>
<ol style="list-style-type: decimal">
<li><strong>Unbiasdness</strong>: Conditional on the explantory variables <span class="math inline">\(X\)</span>, the expectation of the OLS estimator <span class="math inline">\(\hat{\beta}\)</span> is equal to the true value <span class="math inline">\(\beta\)</span>. <span class="math display">\[
E[\hat{\beta} | X] = \beta
\]</span></li>
<li><strong>Consistency</strong>: As the sample size <span class="math inline">\(N\)</span> goes to infinity, the OLS estimator <span class="math inline">\(\hat{\beta}\)</span> converges to <span class="math inline">\(\beta\)</span> in probability <span class="math display">\[
\hat{\beta}\overset{p}{\longrightarrow}\beta
\]</span></li>
<li><strong>Asymptotic normality</strong>: Will talk this <a href="#Statistical-Inference">later</a></li>
</ol>
</div>
<div id="interpretation-and-specifications-of-linear-regression-model" class="section level2">
<h2><span class="header-section-number">8.3</span> Interpretation and Specifications of Linear Regression Model</h2>
<ul>
<li>Remember that <span class="math display">\[ 
Y_{i}=\beta_{0}+\beta_{1}X_{1i}+\cdots+\beta_{K}X_{Ki}+\epsilon_{i} 
\]</span></li>
<li>The coefficient <span class="math inline">\(\beta_k\)</span> captures the effect of <span class="math inline">\(X_k\)</span> on <span class="math inline">\(Y\)</span> <strong>ceteris paribus (all things being equal)</strong></li>
<li>Equivalently, <span class="math display">\[
\frac{\partial Y}{\partial X_k} = \beta_k 
    \]</span> if <span class="math inline">\(X_k\)</span> is continuous random variable.</li>
<li>If we can estimate <span class="math inline">\(\beta_k\)</span> without bias, we can obtain <strong>causal effect</strong> of <span class="math inline">\(X_k\)</span> on <span class="math inline">\(Y\)</span>.
<ul>
<li>This is of course very difficult task. We will see this more later.</li>
</ul></li>
<li>We will see several specifications that are frequently used in empirical analysis. 1. Nonlinear term 1. log specification 2. dummy (categorical) variables 3. interaction terms</li>
</ul>
<div id="nonlinear-term" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Nonlinear term</h3>
<ul>
<li>We can capture non-linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> in a linearly additive form <span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \beta_2 X_i^2 + \beta_3 X_i^3 + \epsilon_i
\]</span></li>
<li>As long as the error term <span class="math inline">\(\epsilon_i\)</span> appreas in a additively linear way, we can estimate the coefficients by OLS.
<ul>
<li>Multicollinarity could be an issue if we have many polynomials (see later).</li>
<li>You can use other non-linear variables such as <span class="math inline">\(log(x)\)</span> and <span class="math inline">\(\sqrt{x}\)</span>.</li>
</ul></li>
</ul>
</div>
<div id="log-specification" class="section level3">
<h3><span class="header-section-number">8.3.2</span> log specification</h3>
<ul>
<li>We often use <code>log</code> variables in both dependent and independent variables.</li>
<li>Using <code>log</code> changes the interpretation of the coefficient <span class="math inline">\(\beta\)</span> in terms of scales.</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Dependent variable</th>
<th align="left">Explanatory variable</th>
<th align="left">interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(Y\)</span></td>
<td align="left"><span class="math inline">\(X\)</span></td>
<td align="left">1 unit increase in <span class="math inline">\(X\)</span> causes <span class="math inline">\(\beta\)</span> units change in Y</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\log Y\)</span></td>
<td align="left"><span class="math inline">\(X\)</span></td>
<td align="left">1 unit increase in <span class="math inline">\(X\)</span> causes <span class="math inline">\(100 \beta \%\)</span> incchangerease in <span class="math inline">\(Y\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(Y\)</span></td>
<td align="left"><span class="math inline">\(\log X\)</span></td>
<td align="left"><span class="math inline">\(1\%\)</span> increase in <span class="math inline">\(X\)</span> causes <span class="math inline">\(\beta / 100\)</span> unit change in <span class="math inline">\(Y\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\log Y\)</span></td>
<td align="left"><span class="math inline">\(\log X\)</span></td>
<td align="left"><span class="math inline">\(1\%\)</span> increase in <span class="math inline">\(X\)</span> causes <span class="math inline">\(\beta \%\)</span> change in <span class="math inline">\(Y\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="dummy-variable" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Dummy variable</h3>
<ul>
<li>A dummy variable takes only 1 or 0. This is used to express qualititative information</li>
<li>Example: Dummy variable for race <span class="math display">\[
white_{i}=\begin{cases}
1 &amp; if\ white\\
0 &amp; otherwise
\end{cases} 
   \]</span></li>
<li>The coefficient on a dummy variable captures the difference of the outcome <span class="math inline">\(Y\)</span> between categories</li>
<li>Consider the linear regression <span class="math display">\[
Y_i = \beta_0 + \beta_1 white_i + \epsilon_i
\]</span> The coefficient <span class="math inline">\(\beta_1\)</span> captures the difference of <span class="math inline">\(Y\)</span> between white and non-white people.</li>
</ul>
</div>
<div id="interaction-term" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Interaction term</h3>
<ul>
<li>You can add the interaction of two explanatory variables in the regression model.</li>
<li>For example: <span class="math display">\[
wage_i = \beta_0 + \beta_1 educ_i + \beta_2 educ_i \times white_i + \epsilon_i
\]</span> where <span class="math inline">\(wage_i\)</span> is the earnings of person <span class="math inline">\(i\)</span> and <span class="math inline">\(educ_i\)</span> is the years of schooling for person <span class="math inline">\(i\)</span>.</li>
<li>The effect of <span class="math inline">\(educ_i\)</span> is <span class="math display">\[
\frac{\partial wage_i}{\partial educ_i} = \beta_1 + \beta_2 white_i,
\]</span></li>
<li>This allows for heterogenous effects of education across races.</li>
</ul>
</div>
</div>
<div id="measures-of-fit" class="section level2">
<h2><span class="header-section-number">8.4</span> Measures of Fit</h2>
<ul>
<li>We often use <span class="math inline">\(R^2\)</span> as a measure of the model fit.</li>
<li>Denote <strong>the fitted value</strong> as <span class="math inline">\(\hat{y}_i\)</span> <span class="math display">\[
 \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_{i1} + \cdots + \hat{\beta}_K X_{iK}
\]</span>
<ul>
<li>Also called prediction from the OLS regression.</li>
</ul></li>
<li><span class="math inline">\(R^2\)</span> is defined as <span class="math display">\[
R^2 = \frac{SSE}{TSS},
\]</span> where <span class="math display">\[ 
 \  SSE = \sum_i (\hat{y}_i - \bar{y})^2, \ TSS = \sum_i (y_i - \bar{y})^2
\]</span></li>
<li><span class="math inline">\(R^2\)</span> captures the fraction of the variation of <span class="math inline">\(Y\)</span> explained by the regression model.</li>
<li>Adding variables always (weakly) increases <span class="math inline">\(R^2\)</span>.</li>
<li>In a regression model with multiple explanatory variables, we often use <strong>adjusted</strong> <span class="math inline">\(R^2\)</span> that adjusts the number of explanatory variables <span class="math display">\[
\bar{R}^2 = 1 - \frac{N-1}{N-(K+1)} \frac{SSR}{TSS}
\]</span> where <span class="math display">\[
SSR = \sum_i (\hat{y}_i - y_i)^2 (= \sum_i \hat{u}_i^2 ),
\]</span></li>
</ul>
</div>
<div id="statistical-inference" class="section level2">
<h2><span class="header-section-number">8.5</span> Statistical Inference</h2>
<ul>
<li>Notice that the OLS estimators are <strong>random variables</strong>. They depend on the data, which are random variables drawn from some population distribution.</li>
<li>We can conduct statistical inferences regarding those OLS estimators: 1. Hypothesis testing 2. Constructing confidence interval</li>
<li>I first explain the sampling distribution of the OLS estimators.</li>
</ul>
<div id="distribution-of-the-ols-estimators-based-on-asymptotic-theory" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Distribution of the OLS estimators based on asymptotic theory</h3>
<ul>
<li>Deriving the exact (finite-sample) distribution of the OLS estimators is very hard.
<ul>
<li>The OLS estimators depend on the data <span class="math inline">\(Y_i, X_i\)</span> in a complex way.</li>
<li>We typically do not know the distribution of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</li>
</ul></li>
<li>We rely on <strong>asymptotic</strong> argument. We approximate the sampling distribution of the OLS esimator based on the cental limit theorem.</li>
<li>Under the OLS assumption, the OLS estimator has <strong>asymptotic normality</strong> <span class="math display">\[
\sqrt{N}(\hat{\beta}-\beta)\overset{d}{\rightarrow}N\left(0,V \right)    
\]</span> where <span class="math display">\[
\underbrace{V}_{(K+1)\times(K+1)}
 = E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}]^{-1}E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}\epsilon_{i}^{2}]E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}]^{-1}
\]</span> and <span class="math display">\[
\underbrace{\mathbf{x}_{i}}_{(K+1)\times1}=\left(\begin{array}{c}
1\\
X_{i1}\\
\vdots\\
X_{iK}
\end{array}\right)
\]</span></li>
<li>We can <strong>approximate</strong> the distribution of <span class="math inline">\(\hat{\beta}\)</span> by <span class="math display">\[
\hat{\beta} \sim N(\beta, V / N)
\]</span></li>
<li>The above is joint distribution. Let <span class="math inline">\(V_{ij}\)</span> be the <span class="math inline">\((i,j)\)</span> element of the matrix <span class="math inline">\(V\)</span>.</li>
<li>The individual coefficient <span class="math inline">\(\beta_k\)</span> follows <span class="math display">\[
 \hat\beta_k \sim N(\beta_k, V_{kk} / N )
\]</span></li>
</ul>
<div id="estimation-of-asymptotic-variance" class="section level4">
<h4><span class="header-section-number">8.5.1.1</span> Estimation of Asymptotic Variance</h4>
<ul>
<li><span class="math inline">\(V\)</span> is an unknown object. Need to be estimated.</li>
<li>Consider the estimator <span class="math inline">\(\hat{V}\)</span> for <span class="math inline">\(V\)</span> using sample analogues <span class="math display">\[
\hat{V}=\left(\frac{1}{N}\sum_{i=1}^{N}\mathbf{x}_{i}&#39;\mathbf{x}_{i}\right)^{-1}\left(\frac{1}{N}\sum_{i=1}^{N}\mathbf{x}_{i}&#39;\mathbf{x}_{i}\hat{\epsilon}_{i}^{2}\right)\left(\frac{1}{N}\sum_{i=1}^{N}\mathbf{x}_{i}&#39;\mathbf{x}_{i}\right)^{-1}
\]</span> where <span class="math inline">\(\hat{\epsilon}_i = y_i - (\hat{\beta}_0 + \cdots + \hat{\beta}_K X_{iK})\)</span> is the residual.</li>
<li>Technically speaking, <span class="math inline">\(\hat{V}\)</span> converges to <span class="math inline">\(V\)</span> in probability. (Proof is out of the scope of this course)</li>
<li>We often use the (asymptotic) <strong>standard error</strong> <span class="math inline">\(SE(\hat{\beta_k}) = \sqrt{\hat{V}_{kk} / N }\)</span>.</li>
<li>The standard error is an estimator for the standard deviation of the OLS estimator <span class="math inline">\(\hat{\beta_k}\)</span>.</li>
</ul>
</div>
</div>
<div id="hypothesis-testing-2" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Hypothesis testing</h3>
<ul>
<li>OLS estimator is the random variable.</li>
<li>You might want to test a particular hypothesis regarding those coefficients.
<ul>
<li>Does x really affects y?</li>
<li>Is the production technology the constant returns to scale?</li>
</ul></li>
<li><p>Here I explain how to conduct hypothesis testing.</p></li>
<li>Step 1: Consider the null hypothesis <span class="math inline">\(H_{0}\)</span> and the alternative hypothesis <span class="math inline">\(H_{1}\)</span> <span class="math display">\[
H_{0}:\beta_{1}=k,H_{1}:\beta_{1}\neq k
\]</span> where <span class="math inline">\(k\)</span> is the known number you set by yourself.</li>
<li><p>Step 2: Define <strong>t-statistic</strong> by <span class="math display">\[
t_{n}=\frac{\hat{\beta_1}-k}{SE(\hat{\beta_1})}
\]</span></p></li>
<li>Step 3: We reject <span class="math inline">\(H_{0}\)</span> is at <span class="math inline">\(\alpha\)</span>-percent significance level if <span class="math display">\[|t_{n}|&gt;C_{\alpha/2} 
\]</span> where <span class="math inline">\(C_{\alpha/2}\)</span> is the <span class="math inline">\(\alpha/2\)</span> percentile of the standard normal distribution.
<ul>
<li>We say we <strong>fail to reject</strong> <span class="math inline">\(H_0\)</span> if the above does not hold.</li>
</ul></li>
</ul>
<div id="caveats-on-hypothesis-testing" class="section level4">
<h4><span class="header-section-number">8.5.2.1</span> Caveats on Hypothesis Testing</h4>
<ul>
<li>We often say <span class="math inline">\(\hat{\beta}\)</span> is <strong>statistically significant</strong> at <span class="math inline">\(5\%\)</span> level if <span class="math inline">\(|t_{n}|&gt;1.96\)</span> when we set <span class="math inline">\(k=0\)</span>.</li>
<li>Arguing the statistical significance alone is not enough for argument in empirical analysis.</li>
<li>Magnitude of the coefficient is also important.</li>
<li>Case 1: Small but statistically significant coefficient.
<ul>
<li>As the sample size <span class="math inline">\(N\)</span> gets large, the <span class="math inline">\(SE\)</span> decreases.</li>
</ul></li>
<li>Case 2: Large but statistically insignificant coefficient.
<ul>
<li>The variable might have an important (economically meaningful) effect.</li>
<li>But you may not be able to estimate the effect precisely with the sample at your hand.</li>
</ul></li>
</ul>
</div>
<div id="f-test" class="section level4">
<h4><span class="header-section-number">8.5.2.2</span> F test</h4>
<ul>
<li>We often test a composite hypothesis that involves multiple parameters such as <span class="math display">\[
 H_{0}:\beta_{1} + \beta_2 = 0,\ H_{1}:\beta_{1} + \beta_2 \neq 0
\]</span></li>
<li>We use <strong>F test</strong> in such a case (to be added).</li>
</ul>
</div>
</div>
<div id="confidence-interval" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Confidence interval</h3>
<ul>
<li>95% confidence interval <span class="math display">\[
CI_{n}  =\left\{ k:|\frac{\hat{\beta}_{1}-k}{SE(\hat{\beta}_{1})}|\leq1.96\right\} 
=\left[\hat{\beta}_{1}-1.96\times SE(\hat{\beta}_{1}),\hat{\beta_{1}}+1.96\times SE(\hat{\beta}_{1})\right]
\]</span></li>
<li>Interpretation: If you draw many samples (dataset) and construct the 95% CI for each sample, 95% of those CIs will include the true parameter.</li>
</ul>
</div>
<div id="homoskedasticity-vs-heteroskedasticity" class="section level3">
<h3><span class="header-section-number">8.5.4</span> Homoskedasticity vs Heteroskedasticity</h3>
<ul>
<li>So far, we did not put any assumption on the variance of the error term <span class="math inline">\(\epsilon_i\)</span>.</li>
<li>The error term <span class="math inline">\(\epsilon_{i}\)</span> has <strong>heteroskedasticity</strong> if <span class="math inline">\(Var(u_{i}|X_{i})\)</span> depends on <span class="math inline">\(X_{i}\)</span>.</li>
<li>If not, we call <span class="math inline">\(\epsilon_{i}\)</span> has <strong>homoskedasticity</strong>.</li>
<li>This has an important implication on the asymptotic variance.</li>
<li>Remember the asymptotic variance <span class="math display">\[
\underbrace{V}_{(K+1)\times(K+1)}
 = E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}]^{-1}E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}\epsilon_{i}^{2}]E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}]^{-1}
\]</span> Standard errors based on this is called <strong>heteroskedasticity robust standard errors</strong>/</li>
<li>If homoskedasticity holds, then <span class="math display">\[
V = E[\mathbf{x}_{i}&#39;\mathbf{x}_{i}]^{-1}\sigma^{2}
\]</span> where <span class="math inline">\(\sigma^2 = V(\epsilon_i)\)</span>.</li>
<li>In many statistical packages (including R and Stata), the standard errors for the OLS estimators are calcualted under homoskedasticity assumption as a default.</li>
<li>However, if the error has heteroskedasticity, the standard error under homoskedasticity assumption will be <strong>underestimated</strong>.</li>
<li>In OLS, <strong>we should always use heteroskedasticity robust standard error.</strong>
<ul>
<li>We will see how to fix this in R.</li>
</ul></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="a-review-of-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-regression-2-implementation-in-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Econometrics_using_R.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
