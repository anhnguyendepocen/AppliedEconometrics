<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>10 Linear Regression 3: Discussions on OLS Assumptions | Lecture Note for Applied Econometrics</title>
  <meta name="description" content="10 Linear Regression 3: Discussions on OLS Assumptions | Lecture Note for Applied Econometrics">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="10 Linear Regression 3: Discussions on OLS Assumptions | Lecture Note for Applied Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10 Linear Regression 3: Discussions on OLS Assumptions | Lecture Note for Applied Econometrics" />
  
  
  

<meta name="author" content="Yuta Toyama">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linear-regression-2-implementation-in-r.html">
<link rel="next" href="exercise-2-problem-set-3.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#about-this"><i class="fa fa-check"></i><b>1.1</b> About this</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#update-april-23-2019"><i class="fa fa-check"></i><b>1.2</b> Update: April 23, 2019</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#update-april-16-2019"><i class="fa fa-check"></i><b>1.3</b> Update: April 16, 2019</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#acknowledgement-as-of-april-16-2019"><i class="fa fa-check"></i><b>1.4</b> Acknowledgement (as of April 16, 2019)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html"><i class="fa fa-check"></i><b>2</b> Introduction to the course</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#what-is-econometrics"><i class="fa fa-check"></i><b>2.1</b> What is econometrics?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#why-do-we-need-to-learn-computation"><i class="fa fa-check"></i><b>2.2</b> Why do we need to learn computation</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-the-course.html"><a href="introduction-to-the-course.html#why-do-we-use-r"><i class="fa fa-check"></i><b>2.3</b> Why do we use R?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html"><i class="fa fa-check"></i><b>3</b> Introduction of <code>R</code> and <code>R studio</code></a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#getting-started"><i class="fa fa-check"></i><b>3.1</b> Getting Started</a></li>
<li class="chapter" data-level="3.2" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#helps"><i class="fa fa-check"></i><b>3.2</b> Helps</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#quick-tour-of-rstudio"><i class="fa fa-check"></i><b>3.3</b> Quick tour of Rstudio</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#basic-calculations"><i class="fa fa-check"></i><b>3.4</b> Basic Calculations</a></li>
<li class="chapter" data-level="3.5" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#getting-help"><i class="fa fa-check"></i><b>3.5</b> Getting Help</a></li>
<li class="chapter" data-level="3.6" data-path="introduction-of-r-and-r-studio.html"><a href="introduction-of-r-and-r-studio.html#installing-packages"><i class="fa fa-check"></i><b>3.6</b> Installing Packages</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-and-programming.html"><a href="data-and-programming.html"><i class="fa fa-check"></i><b>4</b> Data and Programming</a><ul>
<li class="chapter" data-level="4.1" data-path="data-and-programming.html"><a href="data-and-programming.html#data-types"><i class="fa fa-check"></i><b>4.1</b> Data Types</a></li>
<li class="chapter" data-level="4.2" data-path="data-and-programming.html"><a href="data-and-programming.html#data-structures"><i class="fa fa-check"></i><b>4.2</b> Data Structures</a></li>
<li class="chapter" data-level="4.3" data-path="data-and-programming.html"><a href="data-and-programming.html#vectors"><i class="fa fa-check"></i><b>4.3</b> Vectors</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#basics-of-vectors"><i class="fa fa-check"></i><b>4.3.1</b> Basics of vectors</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#useful-functions-for-creating-vectors"><i class="fa fa-check"></i><b>4.3.2</b> Useful functions for creating vectors</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-and-programming.html"><a href="data-and-programming.html#subsetting"><i class="fa fa-check"></i><b>4.3.3</b> Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-and-programming.html"><a href="data-and-programming.html#vectorization"><i class="fa fa-check"></i><b>4.4</b> Vectorization</a></li>
<li class="chapter" data-level="4.5" data-path="data-and-programming.html"><a href="data-and-programming.html#logical-operators"><i class="fa fa-check"></i><b>4.5</b> Logical Operators</a></li>
<li class="chapter" data-level="4.6" data-path="data-and-programming.html"><a href="data-and-programming.html#matrices"><i class="fa fa-check"></i><b>4.6</b> Matrices</a><ul>
<li class="chapter" data-level="4.6.1" data-path="data-and-programming.html"><a href="data-and-programming.html#basics"><i class="fa fa-check"></i><b>4.6.1</b> Basics</a></li>
<li class="chapter" data-level="4.6.2" data-path="data-and-programming.html"><a href="data-and-programming.html#matrix-calculations"><i class="fa fa-check"></i><b>4.6.2</b> Matrix calculations</a></li>
<li class="chapter" data-level="4.6.3" data-path="data-and-programming.html"><a href="data-and-programming.html#getting-information-for-matrix"><i class="fa fa-check"></i><b>4.6.3</b> Getting information for matrix</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="data-and-programming.html"><a href="data-and-programming.html#lists"><i class="fa fa-check"></i><b>4.7</b> Lists</a></li>
<li class="chapter" data-level="4.8" data-path="data-and-programming.html"><a href="data-and-programming.html#data-frames"><i class="fa fa-check"></i><b>4.8</b> Data Frames</a></li>
<li class="chapter" data-level="4.9" data-path="data-and-programming.html"><a href="data-and-programming.html#programming-basics--control-flow-"><i class="fa fa-check"></i><b>4.9</b> Programming Basics -Control flow-</a><ul>
<li class="chapter" data-level="4.9.1" data-path="data-and-programming.html"><a href="data-and-programming.html#ifelse"><i class="fa fa-check"></i><b>4.9.1</b> if/else</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="data-and-programming.html"><a href="data-and-programming.html#for-loop"><i class="fa fa-check"></i><b>4.10</b> <code>for</code> loop</a></li>
<li class="chapter" data-level="4.11" data-path="data-and-programming.html"><a href="data-and-programming.html#functions"><i class="fa fa-check"></i><b>4.11</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-frame.html"><a href="data-frame.html"><i class="fa fa-check"></i><b>5</b> Data frame</a><ul>
<li class="chapter" data-level="5.1" data-path="data-frame.html"><a href="data-frame.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="data-frame.html"><a href="data-frame.html#load-csv-file"><i class="fa fa-check"></i><b>5.2</b> Load csv file</a></li>
<li class="chapter" data-level="5.3" data-path="data-frame.html"><a href="data-frame.html#examine-dataframe"><i class="fa fa-check"></i><b>5.3</b> Examine dataframe</a></li>
<li class="chapter" data-level="5.4" data-path="data-frame.html"><a href="data-frame.html#subsetting-data"><i class="fa fa-check"></i><b>5.4</b> Subsetting data</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="exercise-1.html"><a href="exercise-1.html"><i class="fa fa-check"></i><b>6</b> Exercise 1</a><ul>
<li class="chapter" data-level="6.1" data-path="exercise-1.html"><a href="exercise-1.html#update-as-of-10am-april-18th"><i class="fa fa-check"></i><b>6.1</b> Update (as of 10am, April 18th)</a></li>
<li class="chapter" data-level="6.2" data-path="exercise-1.html"><a href="exercise-1.html#question-examine-the-law-of-large-numbers-through-numerical-simulations"><i class="fa fa-check"></i><b>6.2</b> Question: Examine the law of large numbers through numerical simulations</a><ul>
<li class="chapter" data-level="6.2.1" data-path="exercise-1.html"><a href="exercise-1.html#how-to-implement"><i class="fa fa-check"></i><b>6.2.1</b> How to implement</a></li>
<li class="chapter" data-level="6.2.2" data-path="exercise-1.html"><a href="exercise-1.html#what-to-submit"><i class="fa fa-check"></i><b>6.2.2</b> What to submit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html"><i class="fa fa-check"></i><b>7</b> A Review of Statistics</a><ul>
<li class="chapter" data-level="7.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#estimation"><i class="fa fa-check"></i><b>7.1</b> Estimation</a><ul>
<li class="chapter" data-level="7.1.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#properties-of-the-estimator"><i class="fa fa-check"></i><b>7.1.1</b> Properties of the estimator</a></li>
<li class="chapter" data-level="7.1.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#sample-mean-bary-is-unbiased-and-consistent"><i class="fa fa-check"></i><b>7.1.2</b> Sample mean <span class="math inline">\(\bar{Y}\)</span> is unbiased and consistent</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#hypothesis-testing"><i class="fa fa-check"></i><b>7.2</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="7.2.1" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.2.1</b> Central limit theorem</a></li>
<li class="chapter" data-level="7.2.2" data-path="a-review-of-statistics.html"><a href="a-review-of-statistics.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>7.2.2</b> Hypothesis testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html"><i class="fa fa-check"></i><b>8</b> Linear Regression 1: Theory</a><ul>
<li class="chapter" data-level="8.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#regression-framework"><i class="fa fa-check"></i><b>8.1</b> Regression framework</a></li>
<li class="chapter" data-level="8.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#theoretical-properties-of-ols-estimator"><i class="fa fa-check"></i><b>8.2</b> Theoretical Properties of OLS estimator</a></li>
<li class="chapter" data-level="8.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#interpretation-and-specifications-of-linear-regression-model"><i class="fa fa-check"></i><b>8.3</b> Interpretation and Specifications of Linear Regression Model</a><ul>
<li class="chapter" data-level="8.3.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#nonlinear-term"><i class="fa fa-check"></i><b>8.3.1</b> Nonlinear term</a></li>
<li class="chapter" data-level="8.3.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#log-specification"><i class="fa fa-check"></i><b>8.3.2</b> log specification</a></li>
<li class="chapter" data-level="8.3.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#dummy-variable"><i class="fa fa-check"></i><b>8.3.3</b> Dummy variable</a></li>
<li class="chapter" data-level="8.3.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#interaction-term"><i class="fa fa-check"></i><b>8.3.4</b> Interaction term</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#measures-of-fit"><i class="fa fa-check"></i><b>8.4</b> Measures of Fit</a></li>
<li class="chapter" data-level="8.5" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#statistical-inference"><i class="fa fa-check"></i><b>8.5</b> Statistical Inference</a><ul>
<li class="chapter" data-level="8.5.1" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#distribution-of-the-ols-estimators-based-on-asymptotic-theory"><i class="fa fa-check"></i><b>8.5.1</b> Distribution of the OLS estimators based on asymptotic theory</a></li>
<li class="chapter" data-level="8.5.2" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>8.5.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="8.5.3" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#confidence-interval"><i class="fa fa-check"></i><b>8.5.3</b> Confidence interval</a></li>
<li class="chapter" data-level="8.5.4" data-path="linear-regression-1-theory.html"><a href="linear-regression-1-theory.html#homoskedasticity-vs-heteroskedasticity"><i class="fa fa-check"></i><b>8.5.4</b> Homoskedasticity vs Heteroskedasticity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html"><i class="fa fa-check"></i><b>9</b> Linear Regression 2: Implementation in R</a><ul>
<li class="chapter" data-level="9.1" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#implementation-in-r"><i class="fa fa-check"></i><b>9.1</b> Implementation in R</a><ul>
<li class="chapter" data-level="9.1.1" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#preliminary-packages"><i class="fa fa-check"></i><b>9.1.1</b> Preliminary: packages</a></li>
<li class="chapter" data-level="9.1.2" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#empirical-setting-data-from-california-school"><i class="fa fa-check"></i><b>9.1.2</b> Empirical setting: Data from California School</a></li>
<li class="chapter" data-level="9.1.3" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#step-1-descriptive-analysis"><i class="fa fa-check"></i><b>9.1.3</b> Step 1: Descriptive analysis</a></li>
<li class="chapter" data-level="9.1.4" data-path="linear-regression-2-implementation-in-r.html"><a href="linear-regression-2-implementation-in-r.html#step-2-run-regression"><i class="fa fa-check"></i><b>9.1.4</b> Step 2: Run regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html"><i class="fa fa-check"></i><b>10</b> Linear Regression 3: Discussions on OLS Assumptions</a><ul>
<li class="chapter" data-level="10.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#endogeneity-problem"><i class="fa fa-check"></i><b>10.2</b> Endogeneity problem</a><ul>
<li class="chapter" data-level="10.2.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#omitted-variable-bias"><i class="fa fa-check"></i><b>10.2.1</b> Omitted variable bias</a></li>
<li class="chapter" data-level="10.2.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#correlation-v.s.-causality"><i class="fa fa-check"></i><b>10.2.2</b> Correlation v.s. Causality</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#multicollinearity-issue"><i class="fa fa-check"></i><b>10.3</b> Multicollinearity issue</a><ul>
<li class="chapter" data-level="10.3.1" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#perfect-multicollinearity"><i class="fa fa-check"></i><b>10.3.1</b> Perfect Multicollinearity</a></li>
<li class="chapter" data-level="10.3.2" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#imperfect-multicollinearity."><i class="fa fa-check"></i><b>10.3.2</b> Imperfect multicollinearity.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="linear-regression-3-discussions-on-ols-assumptions.html"><a href="linear-regression-3-discussions-on-ols-assumptions.html#lesson-for-an-empirical-analysis"><i class="fa fa-check"></i><b>10.4</b> Lesson for an empirical analysis</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html"><i class="fa fa-check"></i><b>11</b> Exercise 2 (Problem Set 3)</a><ul>
<li class="chapter" data-level="11.1" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#rules"><i class="fa fa-check"></i><b>11.1</b> Rules</a></li>
<li class="chapter" data-level="11.2" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#question-1-omitted-variable-bias"><i class="fa fa-check"></i><b>11.2</b> Question 1: Omitted Variable Bias</a></li>
<li class="chapter" data-level="11.3" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#question-2-empirical-analysis-using-data-from-washington2008-aer"><i class="fa fa-check"></i><b>11.3</b> Question 2: Empirical Analysis using Data from Washington(2008, AER)</a><ul>
<li class="chapter" data-level="11.3.1" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#preliminary-data-cleaning"><i class="fa fa-check"></i><b>11.3.1</b> Preliminary: data cleaning</a></li>
<li class="chapter" data-level="11.3.2" data-path="exercise-2-problem-set-3.html"><a href="exercise-2-problem-set-3.html#questions"><i class="fa fa-check"></i><b>11.3.2</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variable 1: Framework</a><ul>
<li class="chapter" data-level="12.1" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#introduction-endogeneity-problem-and-its-solution"><i class="fa fa-check"></i><b>12.1</b> Introduction: Endogeneity Problem and its Solution</a></li>
<li class="chapter" data-level="12.2" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#examples-of-endogeneity-problem"><i class="fa fa-check"></i><b>12.2</b> Examples of Endogeneity Problem</a><ul>
<li class="chapter" data-level="12.2.1" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#more-on-omitted-variable-bias"><i class="fa fa-check"></i><b>12.2.1</b> More on Omitted Variable Bias</a></li>
<li class="chapter" data-level="12.2.2" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#measurement-error"><i class="fa fa-check"></i><b>12.2.2</b> Measurement error</a></li>
<li class="chapter" data-level="12.2.3" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#simultaneity-or-reverse-causality"><i class="fa fa-check"></i><b>12.2.3</b> Simultaneity (or reverse causality)</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#idea-of-iv-regression"><i class="fa fa-check"></i><b>12.3</b> Idea of IV Regression</a></li>
<li class="chapter" data-level="12.4" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#formal-framework-and-estimation"><i class="fa fa-check"></i><b>12.4</b> Formal Framework and Estimation</a><ul>
<li class="chapter" data-level="12.4.1" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#model"><i class="fa fa-check"></i><b>12.4.1</b> Model</a></li>
<li class="chapter" data-level="12.4.2" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#estimation-by-two-stage-least-squares-2sls"><i class="fa fa-check"></i><b>12.4.2</b> Estimation by Two Stage Least Squares (2SLS)</a></li>
<li class="chapter" data-level="12.4.3" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#conditions-for-valid-ivs-in-a-general-framework"><i class="fa fa-check"></i><b>12.4.3</b> Conditions for Valid IVs in a general framework</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#check-instrument-validity"><i class="fa fa-check"></i><b>12.5</b> Check Instrument Validity</a><ul>
<li class="chapter" data-level="12.5.1" data-path="instrumental-variable-1-framework.html"><a href="instrumental-variable-1-framework.html#relevance"><i class="fa fa-check"></i><b>12.5.1</b> Relevance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="instrumental-variable-2-implementation-in-r.html"><a href="instrumental-variable-2-implementation-in-r.html"><i class="fa fa-check"></i><b>13</b> Instrumental Variable 2: Implementation in R</a><ul>
<li class="chapter" data-level="13.1" data-path="instrumental-variable-2-implementation-in-r.html"><a href="instrumental-variable-2-implementation-in-r.html#example-1-wage-regression"><i class="fa fa-check"></i><b>13.1</b> Example 1: Wage regression</a><ul>
<li class="chapter" data-level="13.1.1" data-path="instrumental-variable-2-implementation-in-r.html"><a href="instrumental-variable-2-implementation-in-r.html#discussion-on-iv"><i class="fa fa-check"></i><b>13.1.1</b> Discussion on IV</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="instrumental-variable-2-implementation-in-r.html"><a href="instrumental-variable-2-implementation-in-r.html#example-2-estimation-of-the-demand-for-cigaretts"><i class="fa fa-check"></i><b>13.2</b> Example 2: Estimation of the Demand for Cigaretts</a></li>
<li class="chapter" data-level="13.3" data-path="instrumental-variable-2-implementation-in-r.html"><a href="instrumental-variable-2-implementation-in-r.html#example-3-effects-of-turnout-on-partisan-voting"><i class="fa fa-check"></i><b>13.3</b> Example 3: Effects of Turnout on Partisan Voting</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="exercise-3-problem-set-4.html"><a href="exercise-3-problem-set-4.html"><i class="fa fa-check"></i><b>14</b> Exercise 3 (Problem Set 4)</a><ul>
<li class="chapter" data-level="14.1" data-path="exercise-3-problem-set-4.html"><a href="exercise-3-problem-set-4.html#rules-1"><i class="fa fa-check"></i><b>14.1</b> Rules</a></li>
<li class="chapter" data-level="14.2" data-path="exercise-3-problem-set-4.html"><a href="exercise-3-problem-set-4.html#question-demand-estimation"><i class="fa fa-check"></i><b>14.2</b> Question: Demand Estimation</a><ul>
<li class="chapter" data-level="14.2.1" data-path="exercise-3-problem-set-4.html"><a href="exercise-3-problem-set-4.html#questions-1"><i class="fa fa-check"></i><b>14.2.1</b> Questions</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lecture Note for Applied Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression-3-discussions-on-ols-assumptions" class="section level1">
<h1><span class="header-section-number">10</span> Linear Regression 3: Discussions on OLS Assumptions</h1>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">10.1</span> Introduction</h2>
<ul>
<li>Remember that we have four assumptions in OLS estimation</li>
</ul>
<ol style="list-style-type: decimal">
<li>Random sample: <span class="math inline">\(\{ Y_i , X_{i1}, \ldots, X_{iK} \}\)</span> is i.i.d. drawn sample - i.i.d.: identically and independently distributed</li>
<li><span class="math inline">\(\epsilon_i\)</span> has zero conditional mean <span class="math display">\[
  E[ \epsilon_i | X_{i1}, \ldots, X_{iK}] = 0
  \]</span>
<ul>
<li>This implies <span class="math inline">\(Cov(X_{ik}, \epsilon_i) = 0\)</span> for all <span class="math inline">\(k\)</span>. (or <span class="math inline">\(E[\epsilon_i X_{ik}] = 0\)</span>)</li>
<li><strong>No correlation between error term and explanatory variables.</strong></li>
</ul></li>
<li>Large outliers are unlikely:
<ul>
<li>The random variable <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(X_{ik}\)</span> have finite fourth moments.</li>
</ul></li>
<li>No perfect multicollinearity:
<ul>
<li>There is no linear relationship betwen explanatory variables.</li>
</ul></li>
</ol>
<ul>
<li>The OLS estimator has ideal properties (consistency, asymptotic normality, unbiasdness) under these assumptions.</li>
<li>In this chapter, we study the role of these assumptions.</li>
<li>In particular, we focus on the following two assumptions
<ol style="list-style-type: decimal">
<li>No correlation between <span class="math inline">\(\epsilon_{it}\)</span> and <span class="math inline">\(X_{ik}\)</span></li>
<li>No perfect multicollinearity</li>
</ol></li>
</ul>
</div>
<div id="endogeneity-problem" class="section level2">
<h2><span class="header-section-number">10.2</span> Endogeneity problem</h2>
<ul>
<li>When <span class="math inline">\(Cov(x_k, \epsilon)=0\)</span> does not hold, we have <strong>endogeneity problem</strong>
<ul>
<li>We call such <span class="math inline">\(x_k\)</span> an <strong>endogenous variable</strong>.</li>
</ul></li>
<li>There are several cases in which we have endogeneity problem
<ol style="list-style-type: decimal">
<li>Omitted variable bias</li>
<li>Measurement error</li>
<li>Simultaneity</li>
<li>Sample selection</li>
</ol></li>
<li>Here, I focus on the omitted variable bias.</li>
</ul>
<div id="omitted-variable-bias" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Omitted variable bias</h3>
<ul>
<li>Consider the wage regression equation (true model) <span class="math display">\[
\begin{aligned}
\log W_{i}  &amp;=&amp;  &amp; \beta_{0}+\beta_{1}S_{i}+\beta_{2}A_{i}+u_{i} \\
E[u_{i}|S_{i},A_{i}]    &amp;=&amp; &amp; 0
\end{aligned}
\]</span> where <span class="math inline">\(W_{i}\)</span> is wage, <span class="math inline">\(S_{i}\)</span> is the years of schooling, and <span class="math inline">\(A_{i}\)</span> is the ability.</li>
<li>What we want to know is <span class="math inline">\(\beta_1\)</span>, the effect of the schooling on the wage <strong>holding other things fixed</strong>. Also called the returns from education.</li>
<li>An issue is that we do not often observe the ability of a person directly.</li>
<li>Suppose that you omit <span class="math inline">\(A_i\)</span> and run the following regression instead. <span class="math display">\[
\log W_{i}  =   \alpha_{0}+\alpha_{1} S_{i} + v_i 
\]</span> - Notice that <span class="math inline">\(v_i = \beta_2 A_i + u_i\)</span>, so that <span class="math inline">\(S_i\)</span> and <span class="math inline">\(v_i\)</span> is likely to be correlated.</li>
<li>The OLS estimator <span class="math inline">\(\hat\alpha_1\)</span> will have the bias: <span class="math display">\[ 
E[\hat\alpha_1] = \beta_1 + \beta_2\frac{Cov(S_i, A_i)}{Var(S_i)} \]</span>
<ul>
<li>You can also say <span class="math inline">\(\hat\alpha_1\)</span> is not consistent for <span class="math inline">\(\beta_1\)</span>, i.e., <span class="math display">\[
\hat{\alpha}_{1}\overset{p}{\longrightarrow}\beta_{1}+\beta_{2}\frac{Cov(S_{i},A_{i})}{Var(S_{i})}
\]</span></li>
</ul></li>
<li>This is known as <strong>omitted variable bias formula</strong>.</li>
<li>Omitted variable bias depends on 1. The effect of the omitted variable (<span class="math inline">\(A_i\)</span> here) on the dependent variable: <span class="math inline">\(\beta_2\)</span> 2. Correlation between the omitted variable and the explanatory variable.</li>
<li>This is super-important: You can make a guess regarding the direction and the magnitude of the bias!!</li>
<li>This is crucial when you read an empirical paper and do am empirical exercise.</li>
<li><p>Here is the summary table - <span class="math inline">\(x_1\)</span>: included, <span class="math inline">\(x_2\)</span> omitted. <span class="math inline">\(\beta_2\)</span> is the coefficient on <span class="math inline">\(x_2\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(Cov(x_1, x_2) &gt; 0\)</span></th>
<th align="center"><span class="math inline">\(Cov(x_1, x_2) &lt; 0\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\beta_2 &gt; 0\)</span></td>
<td align="center">Positive bias</td>
<td align="center">Negative bias</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\beta_2 &lt; 0\)</span></td>
<td align="center">Negative bias</td>
<td align="center">Positive bias</td>
</tr>
</tbody>
</table></li>
</ul>
</div>
<div id="correlation-v.s.-causality" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Correlation v.s. Causality</h3>
<ul>
<li>Omitted variable bias is related to a well-known argument of “Correlation or Causality”.</li>
<li>Example: Does the education indeed affect your wage, or the unobserved ability affects both the ducation and the wage, leading to correlation between education and wage?</li>
<li>See <a href="Note_IntermediateSeminar_2018_Lecture1_Intro.pdf">my lecture note from Intermediate Seminar (Fall 2018)</a> for the details.</li>
</ul>
</div>
</div>
<div id="multicollinearity-issue" class="section level2">
<h2><span class="header-section-number">10.3</span> Multicollinearity issue</h2>
<div id="perfect-multicollinearity" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Perfect Multicollinearity</h3>
<ul>
<li>If one of the explanatory variables is a linear combination of other variables, we have perfect multicolinearity.</li>
<li>In this case, you cannot estimate all the coefficients.</li>
<li>For example, <span class="math display">\[
y_i = \beta_0 + \beta_1 x_1 + \beta_2\cdot x_2 + \epsilon_i
\]</span> and <span class="math inline">\(x_2 = 2x_1\)</span>.</li>
<li>These explanatory variables are collinear. You are not able to estimate both <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>.</li>
<li>To see this, the above model can be written as <span class="math display">\[
y_i = \beta_0 + \beta_1 x_1 + \beta_2\cdot2x_1 + \epsilon_i \\
\]</span> and this is the same as <span class="math display">\[
y_i =  \beta_0 + (\beta_1 + 2 \beta_2 ) x_1 + \epsilon_i \\
\]</span></li>
<li>You can estimate the composite term <span class="math inline">\(\beta_1 + 2 \beta_2\)</span> as a coefficient on <span class="math inline">\(x_1\)</span>, but not <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> separately.</li>
</ul>
<div id="some-intuition" class="section level4">
<h4><span class="header-section-number">10.3.1.1</span> Some Intuition</h4>
<ul>
<li>Intuitively speaking, the regression coefficients are estimated by capturing how the variation of the explanatory variable <span class="math inline">\(x\)</span> affects the variation of the dependent variable <span class="math inline">\(y\)</span></li>
<li>Since <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are moving together completely, we cannot say how much the variation of <span class="math inline">\(y\)</span> is due to <span class="math inline">\(x_1\)</span> or <span class="math inline">\(x_2\)</span>, so that <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>.</li>
</ul>
</div>
<div id="dummy-variable-1" class="section level4">
<h4><span class="header-section-number">10.3.1.2</span> Dummy variable</h4>
<ul>
<li>Consider the dummy variables that indicate male and famale. <span class="math display">\[
male_{i}=\begin{cases}
1 &amp; if\ male\\
0 &amp; if\ female
\end{cases},\  
female_{i}=\begin{cases}
1 &amp; if\ female\\
0 &amp; if\ male
\end{cases}
\]</span></li>
<li>If you put both male and female dummies into the regression, <span class="math display">\[
y_i = \beta_0 + \beta_1 famale_i + \beta_2 male_i + \epsilon_i
\]</span></li>
<li>Since <span class="math inline">\(male_i + famale_i = 1\)</span> for all <span class="math inline">\(i\)</span>, we have perfect multicolinarity.</li>
<li>You should always omit the dummy variable of one of the groups in the linear regression.</li>
<li>For example, <span class="math display">\[
y_i = \beta_0 + \beta_1 famale_i +  \epsilon_i
\]</span></li>
<li>In this case, <span class="math inline">\(\beta_1\)</span> is interpreted as the effect of being famale <strong>in comparison with male</strong>.
<ul>
<li>The omitted group is the basis for the comparison.</li>
</ul></li>
<li>You should the same thing when you deal with multiple groups such as <span class="math display">\[
\begin{aligned}
freshman_{i}&amp;=&amp;\begin{cases}
1 &amp; if\ freshman\\
0 &amp; otherwise
\end{cases} \\
sophomore_{i}&amp;=&amp;\begin{cases}
1 &amp; if\ sophomore\\
0 &amp; otherwise
\end{cases} \\
junior_{i}&amp;=&amp;\begin{cases}
1 &amp; if\ junior\\
0 &amp; otherwise
\end{cases} \\
senior_{i}&amp;=&amp;\begin{cases}
1 &amp; if\ senior\\
0 &amp; otherwise
\end{cases} 
\end{aligned}
\]</span> and <span class="math display">\[
y_i = \beta_0 + \beta_1 freshman_i + \beta_2 sophomore_i + \beta_3 junior_i +  \epsilon_i
\]</span></li>
</ul>
</div>
</div>
<div id="imperfect-multicollinearity." class="section level3">
<h3><span class="header-section-number">10.3.2</span> Imperfect multicollinearity.</h3>
<ul>
<li>Though not perfectly co-linear, the correlation between explanatory variables might be very high, which we call imperfect multicollinearity.</li>
<li>How does this affect the OLS estimator?</li>
<li>To see this, we consider the following simple model (with homoskedasticity) <span class="math display">\[
y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \epsilon_i, V(\epsilon_i) = \sigma_2
\]</span></li>
<li>You can show that the conditional variance (not asymptotic variance) is given by <span class="math display">\[
V(\hat\beta_1 | X) = \frac{\sigma^{2}}{N\cdot\hat{V}(x_{1i})\cdot(1-R_{1}^{2})}
\]</span> where <span class="math inline">\(\hat V(x_{1i})\)</span> is the sample variance <span class="math display">\[
\hat V(x_{1i})  =\frac{1}{N}\sum(x_{1i}-\bar{x_{1}})^{2}
\]</span> and <span class="math inline">\(R_{1}^{2}\)</span> is the R-squared in the following regression of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(x_1\)</span>. <span class="math display">\[
x_{1i} = \pi_0 + \pi_1 x_{2i} + u_i 
\]</span></li>
<li>You can see that the variance of the OLS estimator <span class="math inline">\(\hat{\beta}_{1}\)</span> is small if
<ol style="list-style-type: decimal">
<li><span class="math inline">\(N\)</span> is large (i.e., more observations!)</li>
<li><span class="math inline">\(\hat V(x_{1i})\)</span> is large (more variation in <span class="math inline">\(x_{1i}\)</span>!)</li>
<li><span class="math inline">\(R_{1}^{2}\)</span> is small.</li>
</ol></li>
<li>Here, high <span class="math inline">\(R_{1}^{2}\)</span> means that <span class="math inline">\(x_{1i}\)</span> is explained well by other variables in a linear way. – The extreme case is <span class="math inline">\(R_{1}^{2}=1\)</span>, that is <span class="math inline">\(x_{1i}\)</span> is the linear combination of other variables, implying perfect multicolinearity!!</li>
</ul>
</div>
</div>
<div id="lesson-for-an-empirical-analysis" class="section level2">
<h2><span class="header-section-number">10.4</span> Lesson for an empirical analysis</h2>
<ul>
<li>We often say <strong>the variation of the variable of interest is important in an empirical analysis</strong>.</li>
<li>This has two meanings:
<ol style="list-style-type: decimal">
<li><strong>exogenous</strong> variation (i.e., uncorrelated with error term)</li>
<li>large variance</li>
</ol></li>
<li>The former is a key for mean independence assumption.</li>
<li><p>The latter is a key for precise estimation (smaller standard error).</p></li>
<li>If we have more variation, the standard error of the OLS estimator is small, meaning that we can precisely estimate the coefficient.</li>
<li>The variation of the variable <strong>after controlling for other factors that affects <span class="math inline">\(y\)</span></strong> is also crucial (corresponding to <span class="math inline">\(1-R_1^2\)</span> above).
<ul>
<li>If you do not include other variables (say <span class="math inline">\(x_2\)</span> above), you will have omitted variable bias.</li>
</ul></li>
<li>To address research questions using data, it is important to find a good variation of the explanatory variable that you want to focus on. This is often called <strong>identification strategy</strong>.
<ul>
<li>Identification strategy is context-specific. To have a good identification strategy, you should be familiar with the background knowledge of your study.</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-2-implementation-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercise-2-problem-set-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Econometrics_using_R.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
