example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
y = c(rep("Hello", 9), "Goodbye"),
z = rep(c(TRUE, FALSE), 5))
example_data
write.csv(example_data, "temp0424.csv")
install.packages("readr")
library(readr)
example_data_from_csv = read_csv("temp0424.csv")
example_data_from_csv
# Working directory
getwd()
# Change working directory
setwd("C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/")
getwd()
# probably get error
read_csv("temp0424.csv")
# Set again
setwd("C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/Material_Github/")
# Load ggplot2
library(ggplot2)
mpg
mpg
# head()
head(mpg, n = 10)
# head()
head(mpg, n = 5)
# View()
View(mpg)
# str(
str(mpg)
# str(
str(mpg)
names(mpg)
# Pick up a particular variable
displacement <- mpg$displ
displacement
# summary statistics
summary(mpg)
library(readr)
pums2000 <- read_csv("data_pums_2000.csv")
pums2000
pop <- as.vector(pums2000$INCTOT)
pop
# Pop mean and sd
pop_mean = mean(pop)
pop_sd   = sd(pop)
pop_mean
pop_sd
library("ggplot2")
qplot(pop, geom = "density",
xlab = "Income",
ylab = "Density")
library("ggplot2")
qplot(pop, geom = "density",
xlab = "Income",
ylab = "Density")
qplot(pums2000$AGE, geom = "density",
xlab = "AGE",
ylab = "Density")
pop = pums2000$AGE
# define function for simulation
f_simu_CLT = function(Nsamples, samplesize, pop, pop_mean, pop_sd ){
output = numeric(Nsamples)
for (i in 1:Nsamples ){
test <- sample(x = pop, size = samplesize)
output[i] <- ( mean(test) - pop_mean ) / (pop_sd / sqrt(samplesize))
}
return(output)
}
# Run simulation
Nsamples = 2000
result_CLT1 <- f_simu_CLT(Nsamples, 10, pop, pop_mean, pop_sd )
result_CLT2 <- f_simu_CLT(Nsamples, 100, pop, pop_mean, pop_sd )
result_CLT3 <- f_simu_CLT(Nsamples, 1000, pop, pop_mean, pop_sd )
# Random draw from standard normal distribution as comparison
result_stdnorm = rnorm(Nsamples)
# Create dataframe
result_CLT_data <- data.frame(  Ybar_standardized_10 = result_CLT1,
Ybar_standardized_100 = result_CLT2,
Ybar_standardized_1000 = result_CLT3,
Standard_Normal = result_stdnorm)
data_for_plot <- melt(data = result_CLT_data, variable.name = "Variable" )
library("reshape")
data_for_plot <- melt(data = result_CLT_data, variable.name = "Variable" )
fig <-
ggplot(data = data_for_plot) +
xlab("Sample mean") +
geom_line(aes(x = value, colour = variable ),   stat = "density" ) +
geom_vline(xintercept=0 ,colour="black")
plot(fig)
pop_mean = mean(pop)
pop_sd = sd(pop)
# define function for simulation
f_simu_CLT = function(Nsamples, samplesize, pop, pop_mean, pop_sd ){
output = numeric(Nsamples)
for (i in 1:Nsamples ){
test <- sample(x = pop, size = samplesize)
output[i] <- ( mean(test) - pop_mean ) / (pop_sd / sqrt(samplesize))
}
return(output)
}
# Run simulation
Nsamples = 2000
result_CLT1 <- f_simu_CLT(Nsamples, 10, pop, pop_mean, pop_sd )
result_CLT2 <- f_simu_CLT(Nsamples, 100, pop, pop_mean, pop_sd )
result_CLT3 <- f_simu_CLT(Nsamples, 1000, pop, pop_mean, pop_sd )
# Random draw from standard normal distribution as comparison
result_stdnorm = rnorm(Nsamples)
# Create dataframe
result_CLT_data <- data.frame(  Ybar_standardized_10 = result_CLT1,
Ybar_standardized_100 = result_CLT2,
Ybar_standardized_1000 = result_CLT3,
Standard_Normal = result_stdnorm)
library("reshape")
data_for_plot <- melt(data = result_CLT_data, variable.name = "Variable" )
fig <-
ggplot(data = data_for_plot) +
xlab("Sample mean") +
geom_line(aes(x = value, colour = variable ),   stat = "density" ) +
geom_vline(xintercept=0 ,colour="black")
plot(fig)
example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
y = c(rep("Hello", 9), "Goodbye"),
z = rep(c(TRUE, FALSE), 5))
example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
y = c(rep("Hello", 9), "Goodbye"),
z = rep(c(TRUE, FALSE), 5))
# Use "readr" package
library(readr)
pums2000 <- read_csv("data_pums_2000.csv")
write.csv(example_data, "example-data.csv", row.names = FALSE)
# install.packages("readr")
library(readr)
example_data_from_csv = read_csv("example-data.csv")
setwd(dir = "directory path" )
example_data = data.frame(x = c(1, 3, 5, 7, 9, 1, 3, 5, 7, 9),
y = c(rep("Hello", 9), "Goodbye"),
z = rep(c(TRUE, FALSE), 5))
example_data
example_data
example_data
write.csv(example_data, "example-data.csv", row.names = FALSE)
install.packages("readr")
# install.packages("readr")
#library(readr)
#example_data_from_csv = read_csv("example-data.csv")
example_data_from_csv = read.csv("example-data.csv")
example_data_from_csv
getwd()
getwd()
setwd(dir = ""C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/" )
setwd(dir = "C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/" )
getwd()
read.csv("example-data.csv")
setwd("C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/Material_Github")
getwd()
read.csv("C:/Users/Yuta/Dropbox/Teaching/2019S_Applied_Econometrics_JPN_ENG/Material_Github/data/fafa.csv")
read.csv("data/fafa.csv")
library(ggplot2)
mpg
head(mpg, n = 10)
str(mpg)
names(mpg)
View(mpg)
mpg$year
mpg$hwy
dim(mpg)
nrow(mpg)
ncol(mpg)
# Use "readr" package
library(readr)
pums2000 <- read_csv("data_pums_2000.csv")
pums2000
pop <- as.vector(pums2000$INCTOT)
pop_mean = mean(pop)
pop_sd   = sd(pop)
# Average income in population
pop_mean
# Standard deviation of income in population
pop_sd
# income distribution in population
# Note that the unit is in USD.
library("ggplot2")
qplot(pop, geom = "density",
xlab = "Income",
ylab = "Density")
# `log` option specifies which axis is represented in log scale.
qplot(pop, geom = "density",
xlab = "Income",
ylab = "Density",
log = "x")
# Set the seed for the random number. This is needed to maintaine the reproducibility of the results.
set.seed(123)
# draw random sample of 100 observations from the variable pop
test <- sample(x = pop, size = 100)
# Use loop to repeat 2000 times.
Nsamples = 2000
result1 <- numeric(Nsamples)
for (i in 1:Nsamples ){
test <- sample(x = pop, size = 100)
result1[i] <- mean(test)
}
# Simple approach
result1 <- replicate(expr = mean(sample(x = pop, size = 10)), n = Nsamples)
result2 <- replicate(expr = mean(sample(x = pop, size = 100)), n = Nsamples)
result3 <- replicate(expr = mean(sample(x = pop, size = 500)), n = Nsamples)
# Create dataframe
result_data <- data.frame(  Ybar10 = result1,
Ybar100 = result2,
Ybar500 = result3)
install.packages("ggplot2")
install.packages("ggplot2")
rnorm(20)
install.packages("rmarkdown")
install.packages("tidyverse")
install.packages("reshape")
install.packages("bookdown")
class(CASchools)
## # install the AER package (once)
## install.packages("AER")
##
## # load the AER package
library(AER)
# load the the data set in the workspace
data(CASchools)
install.packages("AER")
## # install the AER package (once)
## install.packages("AER")
##
## # load the AER package
library(AER)
# load the the data set in the workspace
data(CASchools)
CASchools
View(CASchools)
# Install package if you have not done so
install.packages( c("AER", "dplyr", "stargazer" ) )
install.packages(c("AER", "dplyr", "stargazer"))
# load packages
load(c("AER", "dplyr", "stargazer" ))
# Install package if you have not done so
# install.packages( c("AER", "dplyr", "stargazer" ) )
# load packages
load("AER")
# load packages
load("AER")
# load packages
load("AER")
# load packages
load("AER")
# Install package if you have not done so
# install.packages( c("AER", "dplyr", "stargazer" ) )
# load packages
library("AER")
library("dplyr")
library("dplyr")
library("stargazer")
install.packages("dplyr")
# Install package if you have not done so
install.packages("AER")
install.packages("AER")
install.packages("stargazer")
# Install package if you have not done so
# install.packages("AER")
# install.packages("dplyr")
# install.packages("stargazer")
# load packages
library("AER")
library("dplyr")
library("stargazer")
# Install package if you have not done so
# install.packages("AER")
# install.packages("dplyr")
# install.packages("stargazer")
# load packages
library("AER")
library("dplyr")
library("stargazer")
head(CASchools)
CASchools %>%
mutate( STR = students / teachers ) %>%
mutate( score = (read + math) / 2 ) -> CASchools
head(CASchools)
summary(CASchools)
summary(CASchools)
CASchools %>%
select(STR, score) %>%
summary()
# compute sample averages of STR and score
avg_STR <- mean(CASchools$STR)
avg_score <- mean(CASchools$score)
# compute sample standard deviations of STR and score
sd_STR <- sd(CASchools$STR)
sd_score <- sd(CASchools$score)
# set up a vector of percentiles and compute the quantiles
quantiles <- c(0.10, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9)
quant_STR <- quantile(CASchools$STR, quantiles)
quant_score <- quantile(CASchools$score, quantiles)
# gather everything in a data.frame
DistributionSummary <- data.frame(Average = c(avg_STR, avg_score),
StandardDeviation = c(sd_STR, sd_score),
quantile = rbind(quant_STR, quant_score))
# print the summary to the console
DistributionSummary
stargazer(CASchools, type = "text")
stargazer(CASchools, type = "html")
stargazer(CASchools, type = "text")
CASchools %>%
stargazer( type = "text", summary.stat = c("n", "p75", "sd") )
plot(score ~ STR,
data = CASchools,
main = "Scatterplot of TestScore and STR",
xlab = "STR (X)",
ylab = "Test Score (Y)")
cor(CASchools$STR, CASchools$score)
# load the stargazer library
library(stargazer)
# estimate different model specifications
spec1 <- lm(score ~ size, data = CASchools)
CASchools %>%
dplyr::rename( size = STR) -> CASchools
lm( score ~ size, data = CASchools)
model1_summary <- lm( score ~ size, data = CASchools)
# First, we rename the variable `STR`
CASchools %>%
dplyr::rename( size = STR) -> CASchools
CASchools
CASchools %>%
mutate( STR = students / teachers ) %>%
mutate( score = (read + math) / 2 ) -> CASchools
# First, we rename the variable `STR`
CASchools %>%
dplyr::rename( size = STR) -> CASchools
# Run regression and save results in the varaiable `model1_summary`
model1_summary <- lm( score ~ size, data = CASchools)
# See the results
summary(model1_summary)
summary(CASchools)
# compute heteroskedasticity-robust standard errors
vcov <- vcovHC(linear_model, type = "HC1")
# compute heteroskedasticity-robust standard errors
vcov <- vcovHC(model1_summary, type = "HC1")
vcov
# compute heteroskedasticity-robust standard errors
vcov <- vcovHC(model1_summary, type = "HC1")
# get standard error: the square root of the diagonal element in vcov
robust_se <- sqrt(diag(vcov))
robust_se
model1_summary$coefficients
summary(model1_summary)
model1_summary3
model1_summary
lmtest
?lmtest
# load `lmtest`
load(lmtest)
install.packages("lmtest")
install.packages("lmtest")
library("lmtest")
# load `lmtest`
library(lmtest)
# Combine robust standard errors
coeftest(model1_summary, vcov. = vcov)
stargazer(model1_summary, type ="text")
# load
library(stargazer)
stargazer::stargazer(model1_summary, type ="text")
stargazer::stargazer(model1_summary, type ="latex")
model1_summary
# Install package if you have not done so
# install.packages("AER")
# install.packages("dplyr")
# install.packages("stargazer")
# install.packages("lmtest")
# load packages
library("AER")
library("dplyr")
library("stargazer")
library("lmtest")
# load the the data set in the workspace
data(CASchools)
class(CASchools)
head(CASchools)
CASchools %>%
mutate( STR = students / teachers ) %>%
mutate( score = (read + math) / 2 ) -> CASchools
summary(CASchools)
CASchools %>%
select(STR, score) %>%
summary()
# compute sample averages of STR and score
avg_STR <- mean(CASchools$STR)
avg_score <- mean(CASchools$score)
# compute sample standard deviations of STR and score
sd_STR <- sd(CASchools$STR)
sd_score <- sd(CASchools$score)
# set up a vector of percentiles and compute the quantiles
quantiles <- c(0.10, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9)
quant_STR <- quantile(CASchools$STR, quantiles)
quant_score <- quantile(CASchools$score, quantiles)
# gather everything in a data.frame
DistributionSummary <- data.frame(Average = c(avg_STR, avg_score),
StandardDeviation = c(sd_STR, sd_score),
quantile = rbind(quant_STR, quant_score))
# print the summary to the console
DistributionSummary
stargazer(CASchools, type = "text")
CASchools %>%
stargazer( type = "text", summary.stat = c("n", "p75", "sd") )
plot(score ~ STR,
data = CASchools,
main = "Scatterplot of TestScore and STR",
xlab = "STR (X)",
ylab = "Test Score (Y)")
cor(CASchools$STR, CASchools$score)
# First, we rename the variable `STR`
CASchools %>%
dplyr::rename( size = STR) -> CASchools
# Run regression and save results in the varaiable `model1_summary`
model1_summary <- lm( score ~ size, data = CASchools)
# See the results
summary(model1_summary)
# compute heteroskedasticity-robust standard errors
vcov <- vcovHC(model1_summary, type = "HC1")
# get standard error: the square root of the diagonal element in vcov
robust_se <- sqrt(diag(vcov))
robust_se
# load `lmtest`
library(lmtest)
# Combine robust standard errors
coeftest(model1_summary, vcov. = vcov)
# load
library(stargazer)
stargazer::stargazer(model1_summary, type ="text")
# Create output by stargazer
stargazer::stargazer(model1_summary, type ="text")
rob_se <- list( sqrt(diag(vcovHC(model1_summary, type = "HC1") ) ) )
stargazer( model1_summary,
se = rob_se)
stargazer( model1_summary,
se = rob_se,
type = "text")
# load the stargazer library
# estimate different model specifications
spec1 <- lm(score ~ size, data = CASchools)
spec2 <- lm(score ~ size + english, data = CASchools)
spec3 <- lm(score ~ size + english + lunch, data = CASchools)
spec4 <- lm(score ~ size + english + calworks, data = CASchools)
spec5 <- lm(score ~ size + english + lunch + calworks, data = CASchools)
# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(spec1, type = "HC1"))),
sqrt(diag(vcovHC(spec2, type = "HC1"))),
sqrt(diag(vcovHC(spec3, type = "HC1"))),
sqrt(diag(vcovHC(spec4, type = "HC1"))),
sqrt(diag(vcovHC(spec5, type = "HC1"))))
# generate a LaTeX table using stargazer
stargazer(spec1, spec2, spec3, spec4, spec5,
se = rob_se,
digits = 3,
header = F,
column.labels = c("(I)", "(II)", "(III)", "(IV)", "(V)"))
# generate a LaTeX table using stargazer
stargazer(spec1, spec2, spec3, spec4, spec5,
se = rob_se,
digits = 3,
header = F,
column.labels = c("(I)", "(II)", "(III)", "(IV)", "(V)"),
type ="text")
# load the stargazer library
# estimate different model specifications
spec1 <- lm(score ~ size, data = CASchools)
spec2 <- lm(score ~ size + english, data = CASchools)
spec3 <- lm(score ~ size + english + lunch, data = CASchools)
spec4 <- lm(score ~ size + english + calworks, data = CASchools)
spec5 <- lm(score ~ size + english + lunch + calworks, data = CASchools)
# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(spec1, type = "HC1"))),
sqrt(diag(vcovHC(spec2, type = "HC1"))),
sqrt(diag(vcovHC(spec3, type = "HC1"))),
sqrt(diag(vcovHC(spec4, type = "HC1"))),
sqrt(diag(vcovHC(spec5, type = "HC1"))))
# generate a LaTeX table using stargazer
stargazer(spec1, spec2, spec3, spec4, spec5,
se = rob_se,
digits = 3,
header = F,
column.labels = c("(I)", "(II)", "(III)", "(IV)", "(V)"),
type ="text",
keep.stat = c("N"))
Adjusted
help(stargazer)
# load the stargazer library
# estimate different model specifications
spec1 <- lm(score ~ size, data = CASchools)
spec2 <- lm(score ~ size + english, data = CASchools)
spec3 <- lm(score ~ size + english + lunch, data = CASchools)
spec4 <- lm(score ~ size + english + calworks, data = CASchools)
spec5 <- lm(score ~ size + english + lunch + calworks, data = CASchools)
# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(spec1, type = "HC1"))),
sqrt(diag(vcovHC(spec2, type = "HC1"))),
sqrt(diag(vcovHC(spec3, type = "HC1"))),
sqrt(diag(vcovHC(spec4, type = "HC1"))),
sqrt(diag(vcovHC(spec5, type = "HC1"))))
# generate a LaTeX table using stargazer
stargazer(spec1, spec2, spec3, spec4, spec5,
se = rob_se,
digits = 3,
header = F,
column.labels = c("(I)", "(II)", "(III)", "(IV)", "(V)"),
type ="text",
keep.stat = c("N", "adj.rsq"))
